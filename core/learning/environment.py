import math
import os
import random
import logging
from collections import defaultdict
from dataclasses import dataclass
from enum import Enum, auto
from typing import Optional, List, Dict, Any


import numpy as np
import gymnasium as gym
from gymnasium import spaces

from tools.definitions import LOG_DIR
from core.network.operation import Operation, check_operation_isolation
from core.network.net import Net, Network, generate_flows, generate_simple_topology, FlowGenerator, UniDirectionalFlowGenerator

# Importar desde los mÃ³dulos auxiliares
from core.learning.env_utils import ErrorType, SchedulingError, find_next_event_time
from core.learning.env_utils import check_valid_link, check_temp_operations
from core.learning.env_actions import process_step_action

# --------------------------------------------------------------------------- #
#  Entorno TSN / DRL                                                          #
# --------------------------------------------------------------------------- #
class NetEnv(gym.Env):
    """Entorno de simulaciÃ³n TSN para aprendizaje por refuerzo."""
    
    # Usar la constante centralizada en Net
    MIN_SWITCH_GAP = Net.SWITCH_GAP_MIN

    @dataclass
    class GclInfo:
        gcl_cycle: int = 1
        gcl_length: int = 0

    # --------------------------------------------------------------------- #
    #  InicializaciÃ³n                                                       #
    # --------------------------------------------------------------------- #
    def __init__(self, network: Optional[Network] = None, 
                curriculum_enabled: bool = True,
                initial_complexity: float = 0.25,
                curriculum_step: float = 0.05) -> None:
        super().__init__()

        # --- Curriculum Learning Adaptativo ---
        self.curriculum_enabled = curriculum_enabled
        self.initial_complexity = initial_complexity 
        self.curriculum_step = curriculum_step
        self.current_complexity = initial_complexity
        self.consecutive_successes = 0
        self.original_flows = []  # Store the original complete set of flows
        
        # Si se proporciona una red, guardar su estructura original
        if network is not None:
            self.total_flows = len(network.flows)
            self.base_graph = network.graph
            # Guardar todos los flujos originales
            self.original_flows = list(network.flows)
            
            # Registro explÃ­cito para depuraciÃ³n del modo curriculum
            self.logger = logging.getLogger(f"{__name__}.{os.getpid()}")
            self.logger.setLevel(logging.INFO)
            self.logger.info(f"Inicializando entorno con {self.total_flows} flujos (curriculum: {curriculum_enabled}, complejidad inicial: {initial_complexity})")
            
            if curriculum_enabled and initial_complexity < 1.0:
                # En modo curriculum, reducir el nÃºmero inicial de flujos
                active_flows = int(self.total_flows * self.initial_complexity)
                active_flows = max(5, active_flows)  # MÃ­nimo 5 flujos para empezar
                
                # Seleccionar subset de flujos para el nivel de complejidad actual
                active_flows_list = self.original_flows[:active_flows]
                network = Network(network.graph, active_flows_list)
                self.logger.info(f"Modo curriculum ACTIVADO: usando {active_flows}/{self.total_flows} flujos inicialmente")
            else:
                # Si curriculum estÃ¡ desactivado o complejidad es 1.0, usar todos los flujos
                self.logger.info(f"Modo curriculum DESACTIVADO: usando todos los {self.total_flows} flujos")
                self.current_complexity = 1.0  # Forzar complejidad completa
        
        # Si no se entrega una red, construir topologÃ­a y flujos sencillos
        if network is None:
            g = generate_simple_topology()
            f = generate_flows(g, 10)
            network = Network(g, f)
            self.total_flows = len(network.flows)
            self.base_graph = g
            # Crear generador de flujos apropiado
            self.flow_generator = FlowGenerator(g)

        # --- Estructuras base -------------------------------------------- #
        self.graph = network.graph
        self.flows = list(network.flows)               # lista estable
        self.line_graph, self.link_dict = (
            network.line_graph,
            network.links_dict,
        )

        # --- Estados internos ------------------------------------------- #
        self.num_flows: int = len(self.flows)
        # Reloj de referencia global (solo para la observaciÃ³n)
        # Se calcula siempre como el prÃ³ximo evento mÃ¡s cercano
        self.global_time: int = 0
        self.flow_progress: List[int] = [0] * self.num_flows  # hop en curso de cada flujo
        self.flow_completed: List[bool] = [False] * self.num_flows
        self.flow_first_tx: List[int | None] = [None] * self.num_flows
        self.current_flow_idx: int = 0                 # para roundâ€‘robin

        self.links_operations = defaultdict(list)

        #  ğŸ”€  Las estructuras ligadas a GCL ya no se utilizan.  Mantener
        #  Ãºnicamente la planificaciÃ³n de operaciones; el cÃ¡lculo de las
        #  tablas se traslada al *ResAnalyzer*.

        self.temp_operations: List[tuple] = []         # op en construcciÃ³n

        # ğŸ”¹ Placeholder para mantener compatibilidad con cÃ³digo heredado.
        #   Ya no se llena ni se usa, pero evita AttributeError.
        self.links_gcl: dict = {}

        # â±ï¸  NUEVO: reloj "ocupadoâ€‘hasta" por enlace
        #    (cuÃ¡ndo queda libre cada enlace)
        self.link_busy_until = defaultdict(int)
        # â±ï¸â±ï¸ reloj "ocupadoâ€‘hasta" por switch **sÃ³lo para EGRESOS**
        self.switch_busy_until = defaultdict(int)
        
        # ğŸ“Š NUEVO: Registro del Ãºltimo tiempo de llegada por switch
        # Para garantizar separaciÃ³n mÃ­nima entre paquetes
        self.switch_last_arrival = defaultdict(int)

        # â²ï¸  Ãšltimo instante en que **se creÃ³** (primer hop) un paquete
        #     â€“ solo se usa para imponer la separaciÃ³n en el PRIMER enlace
        self.last_packet_start = -Net.PACKET_GAP_EXTRA

        # ğŸš¦ NUEVO: secciÃ³n crÃ­tica global â€“ "una sola cola"
        self.global_queue_busy_until = 0

        # --- Espacios de observaciÃ³n y acciÃ³n --------------------------- #
        self._setup_spaces()

        # --- Logger ------------------------------------------------------ #
        self.logger = logging.getLogger(f"{__name__}.{os.getpid()}")
        self.logger.setLevel(logging.INFO)

        # Cache: Â«Â¿es nodo final?Â»
        self._es_node_cache: Dict[Any, bool] = {}
        
        # Variable para datos de operaciÃ³n
        self.last_operation_info = {}
        self.agent_decisions = {}

        # Orden FIFO inmutable: simplemente el Ã­ndice de creaciÃ³n del flujo
        # (flows ya estÃ¡ en el mismo orden en que se generaron).
        self._fifo_order = list(range(self.num_flows))

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        #  ğŸ“Š  MÃ©tricas de latencia extremo-a-extremo (Âµs) por episodio
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        #   Se irÃ¡n llenando a medida que cada flujo se completa.
        #   Se resumen al final del episodio en environment_impl.step.
        self._latency_samples: list[int] = []

        # â±ï¸  lista para almacenar la latencia de cada flujo completado
        self._flow_latencies: list[int] = []

    # ----------------------------------------------------------------- #
    #  Helper estÃ¡tico (picklable) para muestrear la separaciÃ³n global  #
    # ----------------------------------------------------------------- #
    @staticmethod
    def _next_packet_gap() -> int:
        """
        Devuelve la separaciÃ³n entre paquetes (Âµs) delegando la lÃ³gica
        Ã­ntegramente a ``Net.sample_packet_gap``.  
        Esta versiÃ³n elimina cÃ³digo muerto y evita ramas nunca alcanzadas.
        """
        return Net.sample_packet_gap()

    # --------------------------------------------------------------------- #
    #  ConfiguraciÃ³n de gymnasium                                           #
    # --------------------------------------------------------------------- #
    def _default_gcl_info(self):
        return self.GclInfo()

    def _setup_spaces(self):
        # MODIFICAR LA OBSERVACIÃ“N: Incluir informaciÃ³n de mÃºltiples flujos (hasta 5)
        # Para cada flujo: [perÃ­odo_norm, payload_norm, progreso, tiempo_espera_norm, es_seleccionable]
        # AdemÃ¡s de las caracterÃ­sticas globales originales
        FLUJOS_OBSERVABLES = 5  # NÃºmero de flujos que podemos observar a la vez
        FEATURES_POR_FLUJO = 5  # CaracterÃ­sticas por flujo
        FEATURES_GLOBALES = 4   # CaracterÃ­sticas globales (tiempo, ocupaciÃ³n GCL, etc.)
        
        self.observation_space = spaces.Box(
            low=0.0, 
            high=1.0, 
            shape=(FEATURES_GLOBALES + FLUJOS_OBSERVABLES * FEATURES_POR_FLUJO,), 
            dtype=np.float32
        )
        
        # NUEVO: Almacenar constantes para uso posterior
        self.NUM_FLUJOS_OBSERVABLES = FLUJOS_OBSERVABLES
        self.FEATURES_POR_FLUJO = FEATURES_POR_FLUJO
        self.FEATURES_GLOBALES = FEATURES_GLOBALES

        # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
        # â•‘  ESPACIO DE ACCIÃ“N (3 DIMENSIONES)                                    â•‘
        # â•‘  0. Guard factor [0-4]                                                â•‘
        # â•‘  1. Gap mÃ­nimo en switch [0-3]                                        â•‘
        # â•‘  2. SelecciÃ³n de flujo candidato [0-4]                                â•‘
        # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        self.action_space = spaces.MultiDiscrete([
            5,                 # Guard factor
            4,                 # Gap mÃ­nimo switch
            FLUJOS_OBSERVABLES # SelecciÃ³n de flujo
        ])

    # --------------------------------------------------------------------- #
    #  Utilidades de selecciÃ³n de flujo / enlace                            #
    # --------------------------------------------------------------------- #
    def select_next_flow_by_agent(self, flow_selection):
        """
        Permite que el agente RL seleccione el prÃ³ximo flujo a programar.
        
        Args:
            flow_selection: Ãndice del flujo seleccionado por el agente (0-4)
        """
        # Usar el Ã­ndice de flujo seleccionado por el agente si estÃ¡ disponible
        if hasattr(self, 'current_candidate_flows') and self.current_candidate_flows:
            if 0 <= flow_selection < len(self.current_candidate_flows):
                selected_idx = self.current_candidate_flows[flow_selection]
                if not self.flow_completed[selected_idx]:
                    self.current_flow_idx = selected_idx
                    return

        # Si la selecciÃ³n directa falla, usar FIFO como fallback
        now = self.global_time
        chosen = None  # (idx, wait_time)

        for idx, done in enumerate(self.flow_completed):
            if done:
                continue
            prog = self.flow_progress[idx]
            if prog == 0 or prog >= len(self.flows[idx].path):
                continue
            next_link = self.flows[idx].path[prog]
            if not next_link[0].startswith('S'):
                continue

            prev_link_id = self.flows[idx].path[prog-1]
            prev_ops = self.links_operations[self.link_dict[prev_link_id]]
            if not prev_ops:
                continue  # el hop previo aÃºn no fue programado
            prev_op = prev_ops[-1][1]
            wait_time = now - prev_op.reception_time
            if chosen is None or wait_time > chosen[1]:
                chosen = (idx, wait_time)

        if chosen:
            self.current_flow_idx = chosen[0]
            return
                
        # Si no se encontrÃ³ un flujo adecuado, buscar cualquier flujo no completado
        if self.flow_completed[self.current_flow_idx]:
            for idx, completed in enumerate(self.flow_completed):
                if not completed:
                    self.current_flow_idx = idx
                    return

    def current_flow(self):
        return self.flows[self.current_flow_idx]

    def current_link(self):
        idx = self.flow_progress[self.current_flow_idx]
        flow = self.current_flow()
        return self.link_dict[flow.path[idx]]

    # ----------------------------------------------------------------- #
    #  FIFO helper                                                      #
    # ----------------------------------------------------------------- #
    def _next_fifo_idx(self) -> int | None:
        """
        Devuelve el Ã­ndice del **Ãºnico** flujo que debe programarse ahora
        segÃºn FIFO estricto (el que mÃ¡s tiempo lleva esperando).
        Si no hay flujos pendientes, devuelve None.
        
        Prioridad: 
        1. Paquetes que estÃ¡n esperando en un switch (para transmisiÃ³n inmediata)
        2. Paquetes con mayor tiempo de espera
        """
        best: tuple[int, int, bool, int] | None = None   # (wait_time, -idx, is_in_switch, hop_idx)
        best_idx: int | None = None

        now = self.global_time
        for idx, done in enumerate(self.flow_completed):
            if done:
                continue
            hop_idx = self.flow_progress[idx]
            if hop_idx >= len(self.flows[idx].path):
                continue

            # --- tiempo desde que el paquete estÃ¡ "listo" ---
            if hop_idx == 0:
                ready_t = 0                          # nunca se ha transmitido
                is_in_switch = False
            else:
                prev_link_id = self.flows[idx].path[hop_idx - 1]
                prev_ops = self.links_operations.get(self.link_dict[prev_link_id], [])
                if not prev_ops:
                    continue        # hop previo aÃºn no programado â‡’ no listo
                
                prev_op = prev_ops[-1][1]
                ready_t = prev_op.reception_time
                
                # Determinar si el paquete estÃ¡ esperando en un switch
                # Si el destino del enlace anterior es un switch y el origen del siguiente enlace
                # coincide con ese switch, entonces el paquete estÃ¡ esperando en un switch
                dst_node = prev_link_id[1] if isinstance(prev_link_id, tuple) else prev_link_id.split('-')[1]
                is_in_switch = dst_node.startswith('S') and not dst_node.startswith('SRV')

            wait = now - ready_t
            fifo_rank = -idx               # menor Ã­ndice â‡’ mÃ¡s antiguo
            
            # Prioridad: 1) paquetes en switch, 2) tiempo de espera, 3) Ã­ndice mÃ¡s bajo
            cand = (int(is_in_switch), wait, fifo_rank, hop_idx)

            if (best is None) or (cand > best):
                best = cand
                best_idx = idx

        return best_idx

    # --------------------------------------------------------------------- #
    #  Reinicio                                                             #
    # --------------------------------------------------------------------- #
    def reset(self, *, seed=None, options=None):
        super().reset(seed=seed)
        
        # Si es necesario incrementar la complejidad
        if self.curriculum_enabled and self.consecutive_successes >= 3:
            if self.increase_complexity():
                # Calcular nÃºmero de flujos segÃºn complejidad actual
                num_flows = int(self.total_flows * self.current_complexity)
                num_flows = max(5, min(self.total_flows, num_flows))
                
                if self.original_flows:
                    # Usar un subset consistente de los flujos originales
                    active_flows_list = self.original_flows[:num_flows]
                    network = Network(self.base_graph, active_flows_list)
                    
                    # Actualizar las estructuras con la nueva red
                    self.graph = network.graph
                    self.flows = list(network.flows)
                    self.line_graph, self.link_dict = (
                        network.line_graph,
                        network.links_dict,
                    )
                    self.num_flows = len(self.flows)
                    
                    self.logger.info(f"Curriculum: Incrementando a {num_flows}/{self.total_flows} flujos (complejidad: {self.current_complexity:.2f})")
                
            self.consecutive_successes = 0

        self.global_time = 0
        self.flow_progress = [0] * self.num_flows
        self.flow_completed = [False] * self.num_flows
        self.flow_first_tx = [None] * self.num_flows
        self.current_flow_idx = 0

        self.links_operations.clear()
        self.links_gcl = {}   # reiniciar placeholder
        self.temp_operations.clear()
        self._es_node_cache.clear()
        self.link_busy_until.clear()
        self.switch_busy_until.clear()
        self.switch_last_arrival.clear()    # NUEVO: Limpiar tiempos de llegada
        self.global_queue_busy_until = 0
        self.last_packet_start = -Net.PACKET_GAP_EXTRA

        # Limpiar mÃ©tricas de latencia para el nuevo episodio
        self._latency_samples.clear()

        # â±ï¸  reiniciar latencias e2e acumuladas
        self._flow_latencies.clear()

        return self._get_observation(), {}

    # --------------------------------------------------------------------- #
    #  ObservaciÃ³n                                                          #
    # --------------------------------------------------------------------- #
    def _get_observation(self):
        # Creamos una observaciÃ³n que contenga informaciÃ³n sobre mÃºltiples flujos
        # La observaciÃ³n tendrÃ¡: [caracterÃ­sticas_globales, caracterÃ­sticas_flujo1, caracterÃ­sticas_flujo2, ...]
        
        # 1. CaracterÃ­sticas globales de la red
        global_time_norm = self.global_time / 10000  # Normalizar tiempo global
        
        # Ya no hay GCL dinÃ¡mico â†’ utilizaciÃ³n 0 siempre
        gcl_util_norm = 0.0
        
        # Calcular porcentaje de flujos completados
        completion_rate = sum(self.flow_completed) / self.num_flows
        
        # Nivel de curriculum
        curriculum_norm = self.current_complexity
        
        # Vector de caracterÃ­sticas globales
        global_features = [global_time_norm, gcl_util_norm, completion_rate, curriculum_norm]
        
        # 2. Obtener una lista de flujos candidatos para programar
        candidatos = []
        for idx, completed in enumerate(self.flow_completed):
            if not completed:
                flow = self.flows[idx]
                hop_idx = self.flow_progress[idx]
                
                # Verificar que el flujo tiene un hop vÃ¡lido para programar
                if hop_idx >= len(flow.path):
                    continue
                    
                # Calcular cuÃ¡nto tiempo ha estado esperando (si aplica)
                wait_time = 0
                if hop_idx > 0:
                    prev_link_id = flow.path[hop_idx-1]
                    prev_ops = self.links_operations.get(self.link_dict[prev_link_id], [])
                    if prev_ops:
                        prev_op = prev_ops[-1][1]
                        wait_time = max(0, self.global_time - prev_op.reception_time)
                
                # Normalizar valores - convertir a caracterÃ­sticas significativas 
                period_norm = flow.period / 10000  # PerÃ­odos mÃ¡s cortos â†’ valores mÃ¡s pequeÃ±os
                payload_norm = flow.payload / Net.MTU  # Payloads mÃ¡s pequeÃ±os â†’ valores mÃ¡s pequeÃ±os
                hop_progress = self.flow_progress[idx] / len(flow.path)
                wait_time_norm = min(wait_time / flow.period, 1.0)  # Normalizar por periodo
                
                # Calcular urgencia basada en plazo prÃ³ximo
                # Cuanto menor sea el tiempo hasta el deadline, mayor urgencia (1.0 = muy urgente)
                deadline_remaining = (flow.period - (self.global_time % flow.period)) / flow.period
                urgency = 1.0 - deadline_remaining  # 0.0 = acaba de empezar, 1.0 = casi vencido
                
                # Log del flujo candidato con sus caracterÃ­sticas para depuraciÃ³n
                self.logger.debug(f"Candidato: {flow.flow_id}, Period: {period_norm:.2f}, Payload: {payload_norm:.2f}, Wait: {wait_time_norm:.2f}, Urgency: {urgency:.2f}")
                
                # AÃ±adir a candidatos con sus caracterÃ­sticas
                candidatos.append((idx, [period_norm, payload_norm, hop_progress, wait_time_norm, urgency]))
        
        # 3. Si no hay candidatos, devolver una observaciÃ³n con ceros
        if not candidatos:
            return np.zeros(self.observation_space.shape, dtype=np.float32)
        
        # 4. Ordenar candidatos de forma significativa para el agente
        # Considerar mÃºltiples factores: tiempo espera (FIFO), urgencia, tamaÃ±o payload
        candidatos = sorted(candidatos, key=lambda x: (
            x[1][3],  # Tiempo de espera (mayor primero - FIFO)
            x[1][4],  # Urgencia (mayor primero)
            -x[1][1]  # Payload (menor primero - mÃ¡s rÃ¡pido)
        ), reverse=True)
        
        # Asegurar que tenemos exactamente NUM_FLUJOS_OBSERVABLES candidatos
        if len(candidatos) > self.NUM_FLUJOS_OBSERVABLES:
            candidatos = candidatos[:self.NUM_FLUJOS_OBSERVABLES]
        
        while len(candidatos) < self.NUM_FLUJOS_OBSERVABLES:
            candidatos.append((-1, [0.0, 0.0, 0.0, 0.0, 0.0]))
        
        # 5. Actualizar los Ã­ndices de flujos candidatos para recuperarlos despuÃ©s
        self.current_candidate_flows = [idx for idx, _ in candidatos if idx >= 0]
        
        # Registro para depuraciÃ³n
        if self.current_candidate_flows:
            self.logger.debug(f"Candidatos ordenados: {[self.flows[idx].flow_id for idx in self.current_candidate_flows]}")
        
        # 6. Construir la observaciÃ³n completa concatenando caracterÃ­sticas
        obs = np.array(global_features + [feat for _, feats in candidatos for feat in feats], dtype=np.float32)
        
        return obs

    # ------------------------------------------------------------------ #
    #  MÃ¡scaras de acciÃ³n                                                #
    # ------------------------------------------------------------------ #
    def action_masks(self):
        """
        Genera mÃ¡scaras para el espacio de acciÃ³n MultiDiscreto.
        """
        # Calcular tamaÃ±o total de la mÃ¡scara sumando todas las dimensiones
        mask_size = sum(self.action_space.nvec)
        
        # Crear una mÃ¡scara plana donde todas las acciones estÃ¡n permitidas (0 = permitida)
        mask = np.zeros(mask_size, dtype=np.int8)
        
        try:
            if self.current_flow_idx < len(self.flows) and not self.flow_completed[self.current_flow_idx]:
                flow = self.current_flow()
                hop_idx = self.flow_progress[self.current_flow_idx]
                
                if hop_idx < len(flow.path):
                    link = self.link_dict[flow.path[hop_idx]]
                    
                    # Si es el primer hop, los factores de guard time altos podrÃ­an desperdiciarse
                    if hop_idx == 0:
                        # Ãndice para guard time alto
                        offset = 0  # No offset needed anymore
                        mask[offset + 3] = 1  # Desactivar valores 3 y 4 (factores altos)
                        mask[offset + 4] = 1
        except Exception as e:
            self.logger.warning(f"Error generando mÃ¡scaras de acciÃ³n: {e}")
            
        return mask

    # --------------------------------------------------------------------- #
    #  Comprobaciones de aislamiento y GCL                                  #
    # --------------------------------------------------------------------- #
    def _is_es_source(self, link_id):
        """
        Devuelve True si el **origen** de link_id es una End-Station (ES).
        1) Primero consulta el atributo ``node_type`` del grafo.
        2) Si no existe, usa la convenciÃ³n de nombres:
           E*, C*  = clientes/ES genÃ©ricas  
           SRV*    = servidores (tambiÃ©n ES)  
           S*      = switches
        """
        if link_id in self._es_node_cache:
            return self._es_node_cache[link_id]

        src = link_id[0] if isinstance(link_id, tuple) else link_id.split('-')[0]

        # a) Metadata del grafo (mÃ¡s robusta)
        if self.graph.nodes.get(src, {}).get("node_type") == "ES":
            self._es_node_cache[link_id] = True
            return True

        # b) ConvenciÃ³n de nombres
        is_es = src.startswith(("E", "C", "SRV"))
        self._es_node_cache[link_id] = is_es
        return is_es

    #  â›”  Retirado.  La agrupaciÃ³n de GCL dejÃ³ de ser necesaria.

    def _check_valid_link(self, link, operation):
        return check_valid_link(link, operation, self.current_flow(), self.links_operations)

    def _check_temp_operations(self):
        return check_temp_operations(self.temp_operations, self.links_operations, self.current_flow())

    def _find_next_event_time(self, current_time):
        """Encuentra el siguiente tiempo de evento programado despuÃ©s de current_time"""
        return find_next_event_time(self.link_busy_until, self.switch_busy_until, current_time)

    # MÃ©todo obsoleto: generaciÃ³n dinÃ¡mica de GCL eliminada.
    # Se mantiene para compatibilidad pero no hace nada y devuelve False.
    def add_gating_with_grouping(self, *args, **kwargs):
        return False

    def increase_complexity(self):
        """Incrementa el nivel de dificultad del entorno"""
        if not self.curriculum_enabled or self.current_complexity >= 1.0:
            return False
            
        # Incrementar complejidad gradualmente
        self.current_complexity = min(1.0, self.current_complexity + self.curriculum_step)
        return True

    # --------------------------------------------------------------------- #
    #  MÃ©todo principal step() - delegado al mÃ³dulo environment_impl         #
    # --------------------------------------------------------------------- #
    from core.learning.environment_impl import step  # (sigue igual, pero sin GCL)

    # --------------------------------------------------------------------- #
    #  gym stubs                                                             #
    # --------------------------------------------------------------------- #
    def render(self):
        pass

    def close(self):
        pass

