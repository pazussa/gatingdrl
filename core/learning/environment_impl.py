import math
import numpy as np
from core.learning.env_utils import ErrorType, SchedulingError, find_next_event_time
from core.network.net import Net
from core.network.operation import Operation
# import directo (la funciÃ³n sigue existiendo)
from core.learning.env_actions import process_step_action
import math, statistics as _stat
# Add missing import for logging
import logging


def step(self, action):
    """
    Ejecuta un paso en el entorno con la acciÃ³n dada.
    
    Este mÃ©todo implementa la lÃ³gica principal para:
    - Procesar la acciÃ³n del agente
    - Calcular tiempos de transmisiÃ³n
    - Manejar conflictos
    - Actualizar el estado del entorno
    - Calcular la recompensa
    
    Args:
        action: AcciÃ³n multidimensional del agente RL
        
    Returns:
        Tuple: (observaciÃ³n, recompensa, terminado, truncado, info)
    """
    try:
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        #  Inicializar mÃ©tricas de latencia a 0 â€“ se actualizarÃ¡n al final
        #  del episodio si todos los flujos se completan con Ã©xito.
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        avg_lat = jitter = max_lat = 0

        # NUEVO: Extraer la selecciÃ³n de flujo de la acciÃ³n y aplicarla ANTES de procesar
        flow_selection = int(action[-1])  # La Ãºltima dimensiÃ³n es la selecciÃ³n de flujo
        
        # IMPORTANTE: Aplicar la selecciÃ³n de flujo inmediatamente
        flow_reward_adj = 0.0
        agent_selected = False                     # Controla si se aplicÃ³ la selecciÃ³n RL
        original_flow_idx = self.current_flow_idx  # Guardar para comprobar si cambiÃ³
        
        if hasattr(self, 'current_candidate_flows') and self.current_candidate_flows:
            if 0 <= flow_selection < len(self.current_candidate_flows):
                selected_idx = self.current_candidate_flows[flow_selection]
                if not self.flow_completed[selected_idx]:
                    # Verificar que el flujo seleccionado tiene un hop vÃ¡lido para programar
                    if self.flow_progress[selected_idx] < len(self.flows[selected_idx].path):
                        self.current_flow_idx = selected_idx
                        agent_selected = True
                        
                        # AÃ±adir informaciÃ³n de debug para seguimiento
                        # â†“  Pasa a DEBUG para no saturar la consola
                        self.logger.debug(
                            "Agente seleccionÃ³ flujo %s (idx %d) de candidatos: %s",
                            self.flows[selected_idx].flow_id,
                            selected_idx,
                            [self.flows[idx].flow_id for idx in self.current_candidate_flows],
                        )
                        
                        # Evaluar si la selecciÃ³n fue buena basÃ¡ndose en caracterÃ­sticas
                        selected_flow = self.flows[selected_idx]
                        
                        # Calcular recompensa por selecciÃ³n inteligente
                        period_factor   = 1.0 - (selected_flow.period / 10000)
                        payload_factor  = 1.0 - (selected_flow.payload / Net.MTU)
                        remaining       = len(selected_flow.path) - self.flow_progress[selected_idx]
                        progress_factor = remaining / len(selected_flow.path)

                        flow_reward_adj = (period_factor * 0.15 +
                                           payload_factor * 0.15 +
                                           progress_factor * 0.15)
                        
                        self.logger.debug(f"Flow selection: {flow_selection} â†’ candidate #{selected_idx} (Flow {selected_flow.flow_id})")
                        self.logger.debug(f"Flow reward adjustment: +{flow_reward_adj:.4f}")
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        #  ENFORCE PRIORITY SCHEDULING - IMMEDIATE FORWARDING FROM SWITCHES
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        fifo_idx = self._next_fifo_idx()
        if fifo_idx is None:
            # No quedan flujos pendientes â€“ deberÃ­a terminar normalmente
            return self._get_observation(), 0, True, False, {"success": True}

        # Respetar la selecciÃ³n del agente salvo que no haya seleccionado
        if not agent_selected and self.current_flow_idx != fifo_idx:
            # Priorizar la transmisiÃ³n desde switches
            prev_flow = self.flows[self.current_flow_idx]
            new_flow = self.flows[fifo_idx]
            prev_hop_idx = self.flow_progress[self.current_flow_idx]
            new_hop_idx = self.flow_progress[fifo_idx]
            
            # Verificar si es un cambio a un flujo que estÃ¡ en un switch esperando
            if new_hop_idx > 0:
                prev_link_id = new_flow.path[new_hop_idx - 1]
                dst_node = prev_link_id[1] if isinstance(prev_link_id, tuple) else prev_link_id.split('-')[1]
                is_at_switch = dst_node.startswith('S') and not dst_node.startswith('SRV')
                
                if is_at_switch:
                    self.logger.debug(f"Priorizando transmisiÃ³n inmediata desde switch: flujo {new_flow.flow_id}")
            
            # Actualizar el flujo actual
            self.current_flow_idx = fifo_idx

        # A partir de aquÃ­ TODO el cÃ³digo sigue igual: ya trabajamos con el
        # flujo correcto; si posteriormente no cabe en el perÃ­odo, se lanzarÃ¡
        # el SchedulingError habitual y el episodio terminarÃ¡ "con error".
        
        # Procesar la acciÃ³n y obtener la informaciÃ³n necesaria
        # â‹  Desestructuramos el nuevo elemento `guard_factor`
        (flow, hop_idx, link, gating, trans_time,
         guard_time, guard_factor,                # â† aquÃ­
         offset_us, switch_gap, sw_src,
         is_egress_from_switch, gcl_strategy) = process_step_action(self, action)

        # ------------------------------------------------------------ #
        # 1. Calcular tiempos                                          #
        # ------------------------------------------------------------ #
        if hop_idx == 0:        # ---------- primer hop ----------
            # Registrar *exactamente* el instante en que se libera el primer bit
            # del paquete en el cliente â†’ op.start_time (no global_time).
            if self.flow_first_tx[self.current_flow_idx] is None:
                # El objeto `op` se crea unas lÃ­neas mÃ¡s abajo; de momento
                # guardamos el valor provisional y lo sobrescribiremos enseguida.
                self.flow_first_tx[self.current_flow_idx] = -1

            # Si no se entrega una red, construir topologÃ­a y flujos sencillos
            if self.flow_first_tx[self.current_flow_idx] is None:
                self.flow_first_tx[self.current_flow_idx] = self.global_time
            # â¶  Primer hop: basta con que el enlace estÃ© libre
            # â¡ï¸  SÃ³lo el *primer* enlace respeta Net.PACKET_GAP_EXTRA
            earliest = max(
                self.link_busy_until[link],
                self.global_queue_busy_until,
                self.last_packet_start + self._next_packet_gap()
            )  # Removed offset_us
            # Obtener el switch de destino para este paquete
            dst_node = link.link_id[1] if isinstance(link.link_id, tuple) else link.link_id.split('-')[1]
            if dst_node.startswith('S'):
                # Asegurar separaciÃ³n mÃ­nima de 1Î¼s entre llegadas al switch
                # Calcula el tiempo de llegada *potencial* al switch
                potential_arrival_time = earliest + trans_time + Net.DELAY_PROP
                min_arrival_time = self.switch_last_arrival[dst_node] + switch_gap
                if potential_arrival_time < min_arrival_time:
                    # Ajustar el tiempo de inicio para garantizar 1Î¼s de separaciÃ³n en destino
                    delay = min_arrival_time - potential_arrival_time
                    earliest += delay
                    # Actualizar el tiempo de llegada real
                    arrival_time = min_arrival_time
                else:
                    arrival_time = potential_arrival_time
                # Actualizar el Ãºltimo tiempo de llegada registrado para este switch
                self.switch_last_arrival[dst_node] = arrival_time

            # Re-calcular la ventana tras cualquier retraso aplicado
            latest = earliest + Net.SYNC_ERROR

            # Para el primer hop desde ES, no hay gating. Dequeue es el inicio mÃ¡s temprano.
            offset   = 0            # sin margen de sincronÃ­a
            dequeue  = earliest     # comienza tan pronto el enlace queda libre
            end_time = dequeue + trans_time
            if end_time > flow.period:
                 # Primer hop (sale de una ES): no hay switch para crear espera
                 raise SchedulingError(ErrorType.PeriodExceed, "ExcediÃ³ perÃ­odo")

            # --- Crear objeto Operation para hop_idx == 0 ---
            op_start_time = earliest
            op_gating_time = None # No hay gating desde ES
            op_latest_time = latest # Usamos latest calculado
            op_end_time = end_time
            # Crear la operaciÃ³n AHORA para que 'op' estÃ© definida
            op = Operation(op_start_time, op_gating_time, op_latest_time, op_end_time)

            # â• GUARDAR datos que el visualizador necesita
            op.guard_factor      = guard_factor      # decisiÃ³n RL
            op.min_gap_value     = switch_gap        # decisiÃ³n RL
            op.guard_time        = guard_time        # longitud real del guard-band

            # â±ï¸  ahora sÃ­: fijamos el instante real de partida
            if self.flow_first_tx[self.current_flow_idx] == -1:
                self.flow_first_tx[self.current_flow_idx] = op_start_time

        else:                   # ---------- hops siguientes ----------
            # â·  Resto de hops:
            prev_link_id = flow.path[hop_idx - 1]
            prev_link = self.link_dict[prev_link_id]
            prev_op = self.links_operations[prev_link][-1][1]

            # Tiempo base: cuando el paquete estÃ¡ listo en el nodo actual
            packet_ready_time = prev_op.reception_time

            # Earliest possible start considerando sÃ³lo llegada y disponibilidad del ENLACE
            # âš ï¸  En hops posteriores **no** aplicamos la separaciÃ³n global:
            earliest_possible_start_on_link = max(packet_ready_time,
                                         self.link_busy_until[link],
                                         self.global_queue_busy_until)  # Removed offset_us

            # Earliest start considerando tambiÃ©n la disponibilidad del PUERTO del SWITCH (si aplica)
            if is_egress_from_switch:
                # FCFS se mantiene, pero no registramos la espera (no la decide el agente)
                final_earliest_start = max(earliest_possible_start_on_link,
                                            self.switch_busy_until[sw_src])
            else:
                final_earliest_start = earliest_possible_start_on_link

            # Calcular la ventana 'latest' basada en el inicio mÃ¡s temprano real
            latest = final_earliest_start + Net.SYNC_ERROR

            # Determinar el tiempo real de DEQUEUE (inicio de transmisiÃ³n)
            offset   = 0            # sin margen de sincronÃ­a
            dequeue  = final_earliest_start
            
            # Calcular tiempo de fin de transmisiÃ³n
            end_time = dequeue + trans_time
            if end_time > flow.period:
                # Si no cabe en su periodo, abortar sin intentos de recolocaciÃ³n
                raise SchedulingError(ErrorType.PeriodExceed, "ExcediÃ³ perÃ­odo")

            # --- Crear objeto Operation ---
            # start_time: CuÃ¡ndo podrÃ­a haber empezado (llegada + disponibilidad enlace)
            # gating_time: CuÃ¡ndo empezÃ³ realmente (dequeue), si aplica gating
            # latest_time: LÃ­mite superior de la ventana para gating
            # end_time: CuÃ¡ndo terminÃ³ la transmisiÃ³n
            op_start_time = earliest_possible_start_on_link
            op_gating_time = dequeue if gating and is_egress_from_switch else None 
            # Importante: Si hay gating, latest_time debe ser igual a gating_time
            if gating and is_egress_from_switch:
                op_latest_time = op_gating_time  # Si hay gating, ambos deben ser iguales
            else:
                op_latest_time = latest  # Sin gating, latest_time mantiene su valor normal

            op_end_time = end_time

            op = Operation(op_start_time, op_gating_time, op_latest_time, op_end_time)

            # â• Actualizar tambiÃ©n en la rama "hops > 0"
            op.guard_factor  = guard_factor
            op.min_gap_value = switch_gap
            op.guard_time    = guard_time
            # No guardamos esperas que no sean decisiÃ³n del agente

            # â”€â”€ Nuevo: garantizar separaciÃ³n mÃ­nima entre llegadas al switch destino â”€â”€
            dst_node = link.link_id[1] if isinstance(link.link_id, tuple) \
                       else link.link_id.split('-')[1]
            if dst_node.startswith('S'):                       # sÃ³lo switches reales
                arrival = op.reception_time - Net.DELAY_PROC_RX
                min_arrival = self.switch_last_arrival[dst_node] + switch_gap
                if arrival < min_arrival:
                    delay = min_arrival - arrival
                    op.add(delay)              # ajusta *todos* los tiempos de la operaciÃ³n
                    op.min_gap_wait += delay   # registrar espera por gap mÃ­nimo
                    dequeue   += delay
                    end_time  += delay
                    op_start_time += delay
                    op_end_time   += delay
                    arrival = min_arrival
                # Registrar llegada para el siguiente paquete
                self.switch_last_arrival[dst_node] = arrival

        # --- Regla *unâ€‘soloâ€‘paqueteâ€‘switch* ---
        # 2. Crear operaciÃ³n temporal                                  #
        # ------------------------------------------------------------ #
        # op ya estÃ¡ creado con los tiempos correctos
        self.temp_operations.append((link, op))

        # Resolver conflictos por desplazamiento
        offset = self._check_temp_operations()
        max_iter = 16  # salvaguarda contra bucles infinitos
        while offset is not None and max_iter:
            # Desplazar la operaciÃ³n segÃºn el offset de conflicto
            op_start_time += offset
            
            # Actualizar TODAS las propiedades temporales
            if op_gating_time is not None:
                # Con gating, todo se desplaza por igual
                op_gating_time += offset
                op_latest_time += offset  # latest siempre alineado con gating
            else:
                # Sin gating, latest avanza con start (son independientes)
                op_latest_time += offset
            
            # Tiempo final siempre se recalcula respecto al inicio real
            op_end_time = (op_gating_time if op_gating_time is not None else op_start_time) + trans_time

            # Recrear la operaciÃ³n con los nuevos tiempos
            op = Operation(op_start_time, op_gating_time, op_latest_time, op_end_time)
            
            # Si hay gating, validar que aÃºn estÃ¡ dentro del perÃ­odo del flujo
            if op_gating_time is not None and op_end_time > flow.period:
                # El inicio real ocurrirÃ­a despuÃ©s del final del perÃ­odo
                raise SchedulingError(
                    ErrorType.PeriodExceed, 
                    "Flow cycles into next period"
                )
            
            # Recrear el array de operaciones temporales con la actualizada
            self.temp_operations = [(link, op)]
            
            # Volver a verificar conflictos
            offset = self._check_temp_operations()
            max_iter -= 1
            
            # Use default fixed conflict resolution strategy
            # (previous conflict_strategy action dimension was removed)
            # Apply a small minimum offset to ensure progress
            if offset is not None and offset == 0:
                offset = max(1, int(switch_gap * Net.SWITCH_GAP_MIN))

        if max_iter == 0 and offset is not None:
            raise SchedulingError(
                ErrorType.PeriodExceed,
                "Failed to resolve conflict after 16 iterations"
            )

        #  â›”  Ya no se generan ni reservan reglas GCL durante el scheduling.

        # ---------- REWARD SHAPING ----------
        GB_PEN      = 0.05   # guard-band (sÃ­ la decide RL)

        reward = 1.0
        reward -= GB_PEN * (guard_time / flow.period)

        # NUEVO: AÃ±adir el ajuste de recompensa por selecciÃ³n inteligente de flujo
        reward += flow_reward_adj

    except SchedulingError as e:
        # Un flujo no cabe en su perÃ­odo â”€ cerramos el episodio,
        #  pero entregando TODO lo que sÃ­ se ha programado hasta ahora.
        self.logger.debug(f"Fallo: {e.msg} (flujo {self.current_flow_idx})")

        partial_res = {lnk: ops.copy()          # copia superficial es suficiente
                       for lnk, ops in self.links_operations.items()}

        return self._get_observation(), -1, True, False, {
            "success": False,                  # episodio fallido
            "ScheduleRes": partial_res,        # â† planificaciÃ³n parcial
        }

    # ------------------------------------------------------------ #
    # 3. Avanzar progreso del flujo                                #
    # ------------------------------------------------------------ #
    self.links_operations[link].append((flow, op))
    self.temp_operations.clear()

    # ğŸŒ Registrar sÃ³lo si es el *primer* hop del flujo
    if hop_idx == 0:
        self.last_packet_start = op_start_time

    # â·  Marcar el enlace como ocupado hasta que el paquete estÃ© completamente recibido Y PROCESADO
    # Usar reception_time que ya incluye DELAY_PROP + DELAY_PROC_RX
    self.link_busy_until[link] = op.reception_time  # En lugar de op.end_time + Net.DELAY_PROP
    # ğŸ”’ Mantener la secciÃ³n crÃ­tica ocupada hasta que el frame se recibe
    self.global_queue_busy_until = op.reception_time

    if is_egress_from_switch:                 # â· liberar switch al terminar
        # Mantener el puerto bloqueado tambiÃ©n durante la guard-band escogida
        # para reflejar exactamente la reserva temporal del modelo matemÃ¡tico
        self.switch_busy_until[sw_src] = op.end_time + guard_time

    self.flow_progress[self.current_flow_idx] += 1


    # â¸  El "reloj" global se redefine como el evento mÃ¡s temprano pendiente
    next_events = [*self.link_busy_until.values(),
                  *self.switch_busy_until.values()]
    # Si no quedan eventos pendientes, mantenemos el reloj en lugar de "rebobinar" a 0
    self.global_time = min(next_events, default=self.global_time)

    # Â¿TerminÃ³ este flujo?
    if self.flow_progress[self.current_flow_idx] == len(flow.path):
        self.flow_completed[self.current_flow_idx] = True
        # ---------- verificaciÃ³n latencia extremo-a-extremo ----------
        fst = self.flow_first_tx[self.current_flow_idx]
        e2e_latency = op.reception_time - fst if fst is not None else 0
        
        # NUEVO: Guardar latencia e2e para estadÃ­sticas globales
        self._flow_latencies.append(e2e_latency)

        # â• Registrar la muestra en el acumulador global
        self._latency_samples.append(e2e_latency)
        
        # *Incluir* la propagaciÃ³n y el procesamiento de RX en el presupuesto
        # ğŸ’¡ Tomar el peorâ€‘caso acumulativo sobre la ruta completa
        hops = len(flow.path)
        e2e_budget = (flow.e2e_delay +                      # presupuesto nominal
                      Net.DELAY_PROP   * hops +            # propagaciÃ³n
                      Net.DELAY_PROC_RX * hops +           # procesado RX
                      guard_time        * (hops - 1))      # guardâ€‘band por hop
        if e2e_latency > e2e_budget:
            raise SchedulingError(ErrorType.PeriodExceed,
                                  f"E2E delay {e2e_latency} > {e2e_budget}")
        reward += 2

    # Â¿TerminÃ³ episodio?
    done = all(self.flow_completed)
    
    # DespuÃ©s de procesar un hop de un flujo, si el destino es un switch,
    # inmediatamente preparar el siguiente hop para transmisiÃ³n
    if not done and hop_idx < len(flow.path) - 1:
        dst_node = link.link_id[1] if isinstance(link.link_id, tuple) else link.link_id.split('-')[1]
        if dst_node.startswith('S') and not dst_node.startswith('SRV'):
            # Este paquete llegÃ³ a un switch, marcar como alta prioridad
            # para ser procesado en el siguiente paso
            arrival_time = op.reception_time
            self.switch_last_arrival[dst_node] = min(arrival_time, self.switch_last_arrival[dst_node])
            
            # Actualizar el reloj global para favorecer el procesamiento inmediato
            # de este paquete que acaba de llegar al switch
            if arrival_time < self.global_time:
                next_events = [*self.link_busy_until.values(), *self.switch_busy_until.values(), arrival_time]
                self.global_time = min(next_events)

    # Gestionar el curriculum learning
    if done and all(self.flow_completed):
        # Episodio exitoso: incrementar contador de Ã©xitos consecutivos
        self.consecutive_successes += 1
        # AÃ±adir bonificaciÃ³n de recompensa proporcional al nivel de complejidad
        reward += 5.0 * self.current_complexity

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        #  ã€½ï¸  Calculamos las estadÃ­sticas de latencia del episodio
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if self._latency_samples:
            avg_lat = sum(self._latency_samples) / len(self._latency_samples)
            max_lat = max(self._latency_samples)
            jitter  = _stat.pstdev(self._latency_samples) if len(self._latency_samples) > 1 else 0
            self.logger.info(
                f"â±ï¸  Latencia promedio={avg_lat:.1f} Âµs Â· "
                f"jitter={jitter:.1f} Âµs Â· "
                f"mÃ¡xima={max_lat} Âµs"
            )
        else:
            avg_lat = max_lat = jitter = 0
        
        # Mostrar informaciÃ³n del progreso del curriculum
        if self.curriculum_enabled:
            self.logger.info(f"Ã‰xito con {len(self.flows)}/{self.total_flows} flujos (complejidad: {self.current_complexity:.2f}, Ã©xitos: {self.consecutive_successes}/3)")
    
    info = {
        "success": done,
        "ScheduleRes": self.links_operations.copy() if done else None,
        "curriculum_level": self.current_complexity,
        "num_flows": len(self.flows),

        # â”€â”€â”€ mÃ©tricas de latencia E2E â”€â”€â”€
        "latency_us": {
            "average": avg_lat,
            "jitter" : jitter,
            "maximum": max_lat,
            "samples": self._latency_samples.copy(),
        },
        # NUEVO: AÃ±adir informaciÃ³n sobre selecciÃ³n de flujos
        "flow_selection": {
            "current_flow_idx": self.current_flow_idx,
            "available_candidates": getattr(self, 'current_candidate_flows', []),
            "selected_option": flow_selection,
            "reward_adj": flow_reward_adj
        }
    }

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    #  Al terminar el episodio (todos los flujos entregados) â†’ mÃ©tricas
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if done and self._flow_latencies:
        avg_lat = sum(self._flow_latencies) / len(self._flow_latencies)
        max_lat = max(self._flow_latencies)
        import statistics as _st
        jitter = _st.pstdev(self._flow_latencies) if len(self._flow_latencies) > 1 else 0

        # Log amigable
        self.logger.info(
            f"â±ï¸  Latencia promedio={avg_lat:.0f} Âµs Â· "
            f"jitter={jitter:.0f} Âµs Â· mÃ¡xima={max_lat:.0f} Âµs"
        )

        # AÃ±adir al diccionario `info`
        info["latency_us"] = {
            "average": avg_lat,
            "jitter":  jitter,
            "max":     max_lat,
        }

    return self._get_observation(), reward, done, False, info
